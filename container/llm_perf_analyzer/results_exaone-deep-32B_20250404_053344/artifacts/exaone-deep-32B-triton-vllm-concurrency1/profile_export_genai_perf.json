{
  "request_throughput": {
    "unit": "requests/sec",
    "avg": 0.37624828520978065
  },
  "request_latency": {
    "unit": "ms",
    "avg": 2657.4573304,
    "p25": 2656.14768,
    "p50": 2658.684739,
    "p75": 2666.3198549999997,
    "p90": 2668.1627562,
    "p95": 2668.7770566,
    "p99": 2669.26849692,
    "min": 2636.7430209999998,
    "max": 2669.391357,
    "std": 11.430395121216195
  },
  "request_count": {
    "unit": "count",
    "avg": 5.0
  },
  "time_to_first_token": {
    "unit": "ms",
    "avg": 84.62658559999998,
    "p25": 86.481753,
    "p50": 86.927022,
    "p75": 88.015276,
    "p90": 89.599747,
    "p95": 90.127904,
    "p99": 90.55042959999999,
    "min": 71.05281599999999,
    "max": 90.656061,
    "std": 6.940009669915585
  },
  "time_to_second_token": {
    "unit": "ms",
    "avg": 26.2926098,
    "p25": 26.093463,
    "p50": 26.212031,
    "p75": 26.297328999999998,
    "p90": 26.7244738,
    "p95": 26.8668554,
    "p99": 26.98076068,
    "min": 25.850989,
    "max": 27.009237,
    "std": 0.38852493783045633
  },
  "inter_token_latency": {
    "unit": "ms",
    "avg": 23.357502999999998,
    "p25": 23.114326,
    "p50": 23.449026,
    "p75": 23.696417999999998,
    "p90": 23.878728,
    "p95": 23.939498,
    "p99": 23.988114,
    "min": 22.527476999999998,
    "max": 24.000268,
    "std": 0.50684610997501
  },
  "output_token_throughput": {
    "unit": "tokens/sec",
    "avg": 41.83880931532761
  },
  "output_token_throughput_per_request": {
    "unit": "tokens/sec",
    "avg": 41.846466123189295,
    "p25": 41.20789546708644,
    "p50": 41.63041421750205,
    "p75": 42.47664603944732,
    "p90": 42.968129668431565,
    "p95": 43.13195754475964,
    "p99": 43.263019845822114,
    "min": 40.621589470822926,
    "max": 43.29578542108773,
    "std": 0.94365532652709
  },
  "output_sequence_length": {
    "unit": "tokens",
    "avg": 111.2,
    "p25": 110.0,
    "p50": 111.0,
    "p75": 112.0,
    "p90": 113.8,
    "p95": 114.4,
    "p99": 114.88,
    "min": 108.0,
    "max": 115.0,
    "std": 2.315167380558045
  },
  "input_sequence_length": {
    "unit": "tokens",
    "avg": 200.2,
    "p25": 200.0,
    "p50": 200.0,
    "p75": 200.0,
    "p90": 200.6,
    "p95": 200.8,
    "p99": 200.96,
    "min": 200.0,
    "max": 201.0,
    "std": 0.4
  },
  "telemetry_stats": {
    "gpu_power_usage": {
      "unit": "W",
      "gpu0": {
        "avg": 272.9008,
        "p25": 285.389,
        "p50": 289.99649999999997,
        "p75": 296.606,
        "p90": 305.94620000000003,
        "p95": 332.012,
        "p99": 332.012,
        "min": 70.306,
        "max": 332.012,
        "std": 68.92540976417914
      },
      "gpu1": {
        "avg": 272.92909999999995,
        "p25": 283.194,
        "p50": 295.0265,
        "p75": 297.119,
        "p90": 300.1153,
        "p95": 317.371,
        "p99": 317.371,
        "min": 76.787,
        "max": 317.371,
        "std": 66.05923198985892
      }
    },
    "gpu_power_limit": {
      "unit": "W",
      "gpu0": {
        "avg": 300.0
      },
      "gpu1": {
        "avg": 300.0
      }
    },
    "energy_consumption": {
      "unit": "MJ",
      "gpu0": {
        "avg": 5.71684619369998,
        "p25": 5.71540108799998,
        "p50": 5.71682439999998,
        "p75": 5.71826274199998,
        "p90": 5.7188971923999805,
        "p95": 5.71942241799998,
        "p99": 5.71942241799998,
        "min": 5.71441008299998,
        "max": 5.71942241799998,
        "std": 0.0016235403444128961
      },
      "gpu1": {
        "avg": 6.297293834800063,
        "p25": 6.295811993000064,
        "p50": 6.297264143500064,
        "p75": 6.298742530000062,
        "p90": 6.299391538600061,
        "p95": 6.2999230930000625,
        "p99": 6.2999230930000625,
        "min": 6.294822836000063,
        "max": 6.2999230930000625,
        "std": 0.0016558969067616567
      }
    },
    "gpu_utilization": {
      "unit": "%",
      "gpu0": {
        "avg": 83.10000000000001,
        "p25": 92.0,
        "p50": 92.0,
        "p75": 93.0,
        "p90": 93.0,
        "p95": 93.0,
        "p99": 93.0,
        "min": 0.0,
        "max": 93.0,
        "std": 27.707219275849393
      },
      "gpu1": {
        "avg": 85.1,
        "p25": 94.0,
        "p50": 94.0,
        "p75": 95.0,
        "p90": 96.0,
        "p95": 96.0,
        "p99": 96.0,
        "min": 0.0,
        "max": 96.0,
        "std": 28.381155719949113
      }
    },
    "total_gpu_memory": {
      "unit": "GB",
      "gpu0": {
        "avg": 85.89934592
      },
      "gpu1": {
        "avg": 85.89934592
      }
    },
    "gpu_memory_used": {
      "unit": "GB",
      "gpu0": {
        "avg": 75.81099622400001,
        "p25": 75.81099622400001,
        "p50": 75.81099622400001,
        "p75": 75.81099622400001,
        "p90": 75.81099622400001,
        "p95": 75.81099622400001,
        "p99": 75.81099622400001,
        "min": 75.81099622400001,
        "max": 75.81099622400001,
        "std": 0.0
      },
      "gpu1": {
        "avg": 75.83196774400001,
        "p25": 75.83196774400001,
        "p50": 75.83196774400001,
        "p75": 75.83196774400001,
        "p90": 75.83196774400001,
        "p95": 75.83196774400001,
        "p99": 75.83196774400001,
        "min": 75.83196774400001,
        "max": 75.83196774400001,
        "std": 0.0
      }
    }
  },
  "input_config": {
    "subcommand": "profile",
    "model": [
      "exaone-deep-32B"
    ],
    "model_selection_strategy": "round_robin",
    "backend": "vllm",
    "endpoint": null,
    "endpoint_type": "kserve",
    "service_kind": "triton",
    "server_metrics_url": [
      "http://localhost:8002/metrics"
    ],
    "streaming": true,
    "u": null,
    "image_width_mean": 100,
    "image_width_stddev": 0,
    "image_height_mean": 100,
    "image_height_stddev": 0,
    "image_format": null,
    "batch_size_image": 1,
    "batch_size_text": 1,
    "goodput": null,
    "header": null,
    "num_dataset_entries": 100,
    "num_prefix_prompts": 0,
    "output_tokens_mean": 100,
    "output_tokens_mean_deterministic": true,
    "output_tokens_stddev": 0,
    "random_seed": 0,
    "request_count": 5,
    "synthetic_input_tokens_mean": 200,
    "synthetic_input_tokens_stddev": 0,
    "prefix_prompt_length": 100,
    "warmup_request_count": 2,
    "verbose": false,
    "artifact_dir": "artifacts/exaone-deep-32B-triton-vllm-concurrency1",
    "generate_plots": false,
    "profile_export_file": "artifacts/exaone-deep-32B-triton-vllm-concurrency1/profile_export.json",
    "concurrency": 1,
    "measurement_interval": 10000,
    "request_rate": null,
    "stability_percentage": 999,
    "tokenizer": "hf-internal-testing/llama-tokenizer",
    "tokenizer_revision": "main",
    "tokenizer_trust_remote_code": false,
    "synthetic_input_files": null,
    "prompt_source": "synthetic",
    "formatted_model_name": "exaone-deep-32B",
    "extra_inputs": {}
  }
}