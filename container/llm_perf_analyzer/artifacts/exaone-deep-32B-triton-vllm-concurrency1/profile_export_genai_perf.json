{
  "request_throughput": {
    "unit": "requests/sec",
    "avg": 0.3773978750677255
  },
  "request_latency": {
    "unit": "ms",
    "avg": 2649.3363035999996,
    "p25": 2638.092768,
    "p50": 2656.709654,
    "p75": 2656.748892,
    "p90": 2657.1309341999995,
    "p95": 2657.2582816,
    "p99": 2657.36015952,
    "min": 2637.7445749999997,
    "max": 2657.385629,
    "std": 9.326196084455926
  },
  "request_count": {
    "unit": "count",
    "avg": 5.0
  },
  "time_to_first_token": {
    "unit": "ms",
    "avg": 90.2230676,
    "p25": 88.611362,
    "p50": 90.410603,
    "p75": 91.3875,
    "p90": 92.8634904,
    "p95": 93.3554872,
    "p99": 93.74908463999999,
    "min": 86.858389,
    "max": 93.847484,
    "std": 2.3852095758394567
  },
  "time_to_second_token": {
    "unit": "ms",
    "avg": 25.538471199999996,
    "p25": 25.472891,
    "p50": 25.510106999999998,
    "p75": 25.679691,
    "p90": 25.6970208,
    "p95": 25.702797399999998,
    "p99": 25.70741868,
    "min": 25.321092999999998,
    "max": 25.708574,
    "std": 0.14229305449585375
  },
  "inter_token_latency": {
    "unit": "ms",
    "avg": 22.991611399999996,
    "p25": 22.315644,
    "p50": 22.508755999999998,
    "p75": 23.386543,
    "p90": 24.430507600000002,
    "p95": 24.778495799999998,
    "p99": 25.05688636,
    "min": 21.62063,
    "max": 25.126483999999998,
    "std": 1.2069236304942579
  },
  "output_token_throughput": {
    "unit": "tokens/sec",
    "avg": 42.49500073262589
  },
  "output_token_throughput_per_request": {
    "unit": "tokens/sec",
    "avg": 42.50369542019044,
    "p25": 41.70229408963906,
    "p50": 43.275615983245764,
    "p75": 43.66303251292359,
    "p90": 44.53022029607302,
    "p95": 44.81928289045616,
    "p99": 45.05053296596267,
    "min": 38.76918903030449,
    "max": 45.1083454848393,
    "std": 2.159301177614574
  },
  "output_sequence_length": {
    "unit": "tokens",
    "avg": 112.6,
    "p25": 110.0,
    "p50": 115.0,
    "p75": 116.0,
    "p90": 117.8,
    "p95": 118.4,
    "p99": 118.88,
    "min": 103.0,
    "max": 119.0,
    "std": 5.607138307550474
  },
  "input_sequence_length": {
    "unit": "tokens",
    "avg": 200.2,
    "p25": 200.0,
    "p50": 200.0,
    "p75": 200.0,
    "p90": 200.6,
    "p95": 200.8,
    "p99": 200.96,
    "min": 200.0,
    "max": 201.0,
    "std": 0.4
  },
  "telemetry_stats": {
    "gpu_power_usage": {
      "unit": "W",
      "gpu0": {
        "avg": 267.52449999999993,
        "p25": 269.27774999999997,
        "p50": 280.595,
        "p75": 284.487,
        "p90": 285.471,
        "p95": 291.825,
        "p99": 291.825,
        "min": 66.508,
        "max": 291.825,
        "std": 47.03959136036367
      },
      "gpu1": {
        "avg": 276.68649999999997,
        "p25": 278.97425,
        "p50": 288.987,
        "p75": 293.13275,
        "p90": 296.9661,
        "p95": 298.281,
        "p99": 298.281,
        "min": 72.814,
        "max": 298.281,
        "std": 47.316242515123704
      }
    },
    "gpu_power_limit": {
      "unit": "W",
      "gpu0": {
        "avg": 300.0
      },
      "gpu1": {
        "avg": 300.0
      }
    },
    "energy_consumption": {
      "unit": "MJ",
      "gpu0": {
        "avg": 5.708831181399979,
        "p25": 5.7075322917499784,
        "p50": 5.708800230999978,
        "p75": 5.710083249999979,
        "p90": 5.711081638999978,
        "p95": 5.7111117406499785,
        "p99": 5.711569285729979,
        "min": 5.706377653999978,
        "max": 5.711683671999978,
        "std": 0.0016218095352584787
      },
      "gpu1": {
        "avg": 6.288929465150064,
        "p25": 6.287616101750063,
        "p50": 6.288895625000063,
        "p75": 6.290191866500063,
        "p90": 6.291231520000063,
        "p95": 6.291260580500063,
        "p99": 6.291702300100064,
        "min": 6.286434791000064,
        "max": 6.291812730000063,
        "std": 0.0016445834221608029
      }
    },
    "gpu_utilization": {
      "unit": "%",
      "gpu0": {
        "avg": 88.35,
        "p25": 93.0,
        "p50": 93.0,
        "p75": 93.0,
        "p90": 93.10000000000001,
        "p95": 94.0,
        "p99": 94.0,
        "min": 0.0,
        "max": 94.0,
        "std": 20.273813158851002
      },
      "gpu1": {
        "avg": 90.35,
        "p25": 95.0,
        "p50": 95.0,
        "p75": 95.0,
        "p90": 95.10000000000001,
        "p95": 96.0,
        "p99": 96.0,
        "min": 0.0,
        "max": 96.0,
        "std": 20.729869753570572
      }
    },
    "total_gpu_memory": {
      "unit": "GB",
      "gpu0": {
        "avg": 85.89934592
      },
      "gpu1": {
        "avg": 85.89934592
      }
    },
    "gpu_memory_used": {
      "unit": "GB",
      "gpu0": {
        "avg": 75.81099622400001,
        "p25": 75.81099622400001,
        "p50": 75.81099622400001,
        "p75": 75.81099622400001,
        "p90": 75.81099622400001,
        "p95": 75.81099622400001,
        "p99": 75.81099622400001,
        "min": 75.81099622400001,
        "max": 75.81099622400001,
        "std": 0.0
      },
      "gpu1": {
        "avg": 75.83196774400001,
        "p25": 75.83196774400001,
        "p50": 75.83196774400001,
        "p75": 75.83196774400001,
        "p90": 75.83196774400001,
        "p95": 75.83196774400001,
        "p99": 75.83196774400001,
        "min": 75.83196774400001,
        "max": 75.83196774400001,
        "std": 0.0
      }
    }
  },
  "input_config": {
    "subcommand": "profile",
    "model": [
      "exaone-deep-32B"
    ],
    "model_selection_strategy": "round_robin",
    "backend": "vllm",
    "endpoint": null,
    "endpoint_type": "kserve",
    "service_kind": "triton",
    "server_metrics_url": [
      "http://localhost:8002/metrics"
    ],
    "streaming": true,
    "u": null,
    "image_width_mean": 100,
    "image_width_stddev": 0,
    "image_height_mean": 100,
    "image_height_stddev": 0,
    "image_format": null,
    "batch_size_image": 1,
    "batch_size_text": 1,
    "goodput": null,
    "header": null,
    "num_dataset_entries": 100,
    "num_prefix_prompts": 0,
    "output_tokens_mean": 100,
    "output_tokens_mean_deterministic": true,
    "output_tokens_stddev": 0,
    "random_seed": 0,
    "request_count": 5,
    "synthetic_input_tokens_mean": 200,
    "synthetic_input_tokens_stddev": 0,
    "prefix_prompt_length": 100,
    "warmup_request_count": 2,
    "verbose": false,
    "artifact_dir": "artifacts/exaone-deep-32B-triton-vllm-concurrency1",
    "generate_plots": false,
    "profile_export_file": "artifacts/exaone-deep-32B-triton-vllm-concurrency1/profile_export.json",
    "concurrency": 1,
    "measurement_interval": 10000,
    "request_rate": null,
    "stability_percentage": 999,
    "tokenizer": "hf-internal-testing/llama-tokenizer",
    "tokenizer_revision": "main",
    "tokenizer_trust_remote_code": false,
    "synthetic_input_files": null,
    "prompt_source": "synthetic",
    "formatted_model_name": "exaone-deep-32B",
    "extra_inputs": {}
  }
}